{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import colorsys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a numpy array with dimensions (height, width, 4)\n",
    "# convert it to a numpy array with dimensions (height, width, 10)\n",
    "# each four-ple of the input array is (b, g, r, a)\n",
    "# b, g, r range from 0 to 255\n",
    "# each ten-ple of the output array is (r, g, b, h, l, s, a, row, col, dist)\n",
    "# r, g, b, h, l, s, a range from 0 to 1\n",
    "\n",
    "def augment(im):\n",
    "    \n",
    "    # find the distance to the center\n",
    "    (height, width, four) = im.shape\n",
    "    (center_x, center_y) = (width // 2, height // 2)\n",
    "    augmented = np.zeros((height, width, 10)) # ten features total\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            [b, g, r, a] = im[row, col]\n",
    "            dist = abs(center_x - row) + abs(center_y - col)\n",
    "            (r, b, g, a) = r / 255, b / 255, g / 255, a / 255\n",
    "            (h, l, s) = colorsys.rgb_to_hls(r, g, b)\n",
    "            augmented[row, col] = [r, g, b, h, l, s, a, row, col, dist]\n",
    "    \n",
    "    return augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a numpy array with dimensions (rows, 10)\n",
    "# convert it to a pandas dataframe with dimensions (?, 10)\n",
    "# cols: r, g, b, h, l, s, a, row, col, dist\n",
    "# r, g, b, h, l, s, a range from 0 to 1\n",
    "# remove all rows where a < 0.5\n",
    "\n",
    "def make_df(im):\n",
    "    \n",
    "    names = [\"r\", \"g\", \"b\", \"h\", \"l\", \"s\", \"a\", \"row\", \"col\", \"center\"]\n",
    "    data = {}\n",
    "    for i in range(len(names)):\n",
    "        col_name = names[i]\n",
    "        column = im[:, i]\n",
    "        data[col_name] = list(column)\n",
    "    \n",
    "    df_all = pd.DataFrame(data)\n",
    "    df = df_all.query(\"a > 0.5\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an object!!\n",
    "# this could technically be a tuple or something, since there aren't actual methods\n",
    "# however it is nice to hide all the initialization behind an __init__\n",
    "\n",
    "class Face():\n",
    "    \n",
    "    def __init__(self, image):\n",
    "        \n",
    "        # keep the og image\n",
    "        self.im = image\n",
    "        \n",
    "        # add a bunch of features\n",
    "        self.augmented = augment(self.im)\n",
    "        \n",
    "        # store a center patch\n",
    "        (height, width, four) = self.im.shape\n",
    "        (center_x, center_y) = (width // 2, height // 2)\n",
    "        dim = min(center_x, center_y) // 2\n",
    "        self.patch = self.im[center_x - dim : center_x + dim, center_y - dim : center_y + dim]\n",
    "        self.patch_augmented = self.augmented[center_x - dim : center_x + dim, center_y - dim : center_y + dim]\n",
    "    \n",
    "        # save flat versions of everything\n",
    "        my_flatten = lambda a, dim: a.transpose(2, 0, 1).reshape(dim, -1).transpose()\n",
    "        self.flat = my_flatten(self.im, 4)\n",
    "        self.augmented_flat = my_flatten(self.augmented, 10)\n",
    "        self.patch_flat = my_flatten(self.patch, 4)\n",
    "        self.patch_augmented_flat = my_flatten(self.patch_augmented, 10)\n",
    "    \n",
    "        # make data frames of each-- these include only the \"valuable\" (opaque) pixels\n",
    "        self.df = make_df(self.augmented_flat)\n",
    "        self.patch_df = make_df(self.patch_augmented_flat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an object, and hyperparameters\n",
    "# fit a kmeans model\n",
    "# determine which label corresponds to skin\n",
    "# determine which pixels are skin and which aren't\n",
    "\n",
    "def fit_model(face, features, n_clusters):\n",
    "\n",
    "    # use the data frame of the full image to fit a model\n",
    "    df = face.df[features]\n",
    "    k_means = KMeans(n_clusters=n_clusters)\n",
    "    k_means.fit(df)\n",
    "\n",
    "    # store the labels (easier image building later on)\n",
    "    label_dict = {}\n",
    "    all_labels = k_means.predict(df)\n",
    "    count = 0\n",
    "    for index, [a, b, center, col, g, h, l, r, row, s] in face.df.iterrows():\n",
    "        key = (row, col)\n",
    "        label = all_labels[count]\n",
    "        label_dict[key] = label\n",
    "        count += 1\n",
    "\n",
    "    # predict labels for the patch df to get the skin label\n",
    "    patch_df = face.patch_df[features]\n",
    "    patch_labels = k_means.predict(patch_df)\n",
    "    c = Counter(patch_labels)\n",
    "    skin_label = c.most_common()[0][0]\n",
    "    \n",
    "    # which pixels are skin?\n",
    "    labels = (all_labels == skin_label)\n",
    "    return skin_label, label_dict, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an object, and information about the labels\n",
    "# create two images\n",
    "# white = transparent\n",
    "# light blue = classified as non skin\n",
    "# dark blue OR original pixel = classified as skin\n",
    "\n",
    "def make_images(face, skin_label, label_dict):\n",
    "\n",
    "    # create blank images to fill in\n",
    "    (height, width, four) = face.im.shape\n",
    "    classified_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    skin_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # loop through and fill in the pixels\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            [r, g, b, h, l, s, a, row, col, dist] = face.augmented[i, j]\n",
    "\n",
    "            # remove the thresholded pixels\n",
    "            if (a <= 0.5):\n",
    "                skin_image[i, j] = [255, 255, 255]\n",
    "                classified_image[i, j] = [255, 255, 255]\n",
    "\n",
    "            # if it's not thresholded, grab the label from the dictionary\n",
    "            else:\n",
    "                label = label_dict[(row, col)]\n",
    "\n",
    "                # color according to if it's skin\n",
    "                if (label == skin_label):\n",
    "                    skin_image[i, j] = [round(b * 255), round(g * 255), round(r * 255)]\n",
    "                    classified_image[i, j] = [255, 0, 0]\n",
    "                else:\n",
    "                    skin_image[i, j] = [255, 240, 180]\n",
    "                    classified_image[i, j] = [255, 240, 180]\n",
    "\n",
    "    return skin_image, classified_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given an object, and information about the labels\n",
    "# get the median color\n",
    "\n",
    "def get_median_color(face, labels):\n",
    "\n",
    "    # identify which pixels are skin\n",
    "    skin_rows = face.df[labels]\n",
    "    skin_pixels = skin_rows[[\"b\", \"g\", \"r\"]] # curse open cv2 and it's bgr format!! why!!??\n",
    "\n",
    "    # take the median of these skin pixels and coerce into numpy array\n",
    "    median_pd = skin_pixels.median(axis=0)\n",
    "    median_np = np.array(median_pd)\n",
    "    \n",
    "    # make a color block\n",
    "    color_block = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "    color_block[:, :] = median_np * 255\n",
    "    return color_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    ([\"g\", \"l\"], 3),\n",
    "    ([\"h\"], 2),\n",
    "    ([\"h\", \"s\"], 2),\n",
    "    ([\"h\", \"s\"], 3),\n",
    "    ([\"r\"], 3),\n",
    "    ([\"r\", \"g\", \"b\"], 2),\n",
    "    ([\"r\", \"g\", \"b\"], 3),\n",
    "    ([\"r\", \"g\", \"b\", \"h\"], 3),\n",
    "    ([\"r\", \"g\", \"b\", \"h\", \"s\"], 2),\n",
    "    ([\"r\", \"g\", \"b\", \"h\", \"s\", \"l\"], 2),\n",
    "    ([\"r\", \"g\", \"b\", \"h\", \"s\", \"l\"], 3),\n",
    "    ([\"r\", \"h\"], 2),\n",
    "    ([\"r\", \"h\", \"s\"], 2),\n",
    "    ([\"s\"], 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a PNG image (ie, four channels) that has been read in with cv2,\n",
    "# identify the skin pixels using the models given,\n",
    "# save images for each model\n",
    "# save a single csv describing the pixels\n",
    "\n",
    "def cluster_face(image, directory, models=MODELS):\n",
    "    \n",
    "    face = Face(image)\n",
    "    cv2.imwrite(directory + \"/0face.png\", image)\n",
    "    os.mkdir(directory + \"/0valid\")\n",
    "    output = face.df.loc[:, [\"r\", \"g\", \"b\", \"row\", \"col\"]]\n",
    "    \n",
    "    for (features, n_clusters) in models:\n",
    "        \n",
    "        # do all the fitting\n",
    "        skin_label, label_dict, labels = fit_model(face, features, n_clusters)\n",
    "        skin_image, classified_image = make_images(face, skin_label, label_dict)\n",
    "        median_color = get_median_color(face, labels)\n",
    "        \n",
    "        # save all the info\n",
    "        model_name = \"\".join(features) + str(n_clusters)\n",
    "        print(model_name, end=\" \")\n",
    "        model_path = directory + \"/\" + model_name + \"_{}.jpg\"\n",
    "        cv2.imwrite(model_path.format(\"skin\"), skin_image)\n",
    "        cv2.imwrite(model_path.format(\"cluster\"), classified_image)\n",
    "        cv2.imwrite(model_path.format(\"color\"), median_color)\n",
    "        output[model_name] = labels\n",
    "        \n",
    "    # save the csv\n",
    "    output.to_csv(directory + \"/0pixels.csv\", index=False)\n",
    "    \n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all the faces, and cluster each one\n",
    "\n",
    "so_far = set(os.listdir(\"all_pictures/median\"))\n",
    "\n",
    "def cluster_faces(face_dir):\n",
    "    \n",
    "    # loop through all faces\n",
    "    count = 0\n",
    "    for image in os.listdir(face_dir):\n",
    "        \n",
    "        print(\"\\n{}/262...\".format(count), end=\" \")\n",
    "        count += 1\n",
    "        \n",
    "        # image paths from os.listdir don't include the name of the directory\n",
    "        # so it needs to be added in\n",
    "        image_path = \"{}/{}\".format(face_dir, image)\n",
    "        \n",
    "        # read the image\n",
    "        face = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # determine the name of the directory\n",
    "        vol_issue_yr_face = image.split(\"_\")[1 :]\n",
    "        joined = \"_\".join(vol_issue_yr_face)\n",
    "        splitted = joined.split(\".\")[0]\n",
    "        \n",
    "        if (splitted not in so_far):\n",
    "            directory = \"all_pictures/median/\" + splitted\n",
    "            print(directory, end=\" \")\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            # cluster!\n",
    "            cluster_face(face, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0/262... \n",
      "1/262... \n",
      "2/262... \n",
      "3/262... \n",
      "4/262... \n",
      "5/262... \n",
      "6/262... \n",
      "7/262... \n",
      "8/262... \n",
      "9/262... \n",
      "10/262... \n",
      "11/262... all_pictures/median/190_11_2000_0 gl3 h2 hs2 hs3 r3 rgb2 rgb3 rgbh3 rgbhs2 rgbhsl2 rgbhsl3 rh2 rhs2 s2 \n",
      "12/262... \n",
      "13/262... \n",
      "14/262... \n",
      "15/262... \n",
      "16/262... \n",
      "17/262... \n",
      "18/262... \n",
      "19/262... \n",
      "20/262... \n",
      "21/262... \n",
      "22/262... \n",
      "23/262... \n",
      "24/262... \n",
      "25/262... \n",
      "26/262... \n",
      "27/262... \n",
      "28/262... \n",
      "29/262... \n",
      "30/262... \n",
      "31/262... \n",
      "32/262... \n",
      "33/262... \n",
      "34/262... \n",
      "35/262... \n",
      "36/262... \n",
      "37/262... \n",
      "38/262... \n",
      "39/262... \n",
      "40/262... \n",
      "41/262... \n",
      "42/262... \n",
      "43/262... \n",
      "44/262... \n",
      "45/262... \n",
      "46/262... \n",
      "47/262... \n",
      "48/262... \n",
      "49/262... \n",
      "50/262... \n",
      "51/262... \n",
      "52/262... \n",
      "53/262... \n",
      "54/262... \n",
      "55/262... \n",
      "56/262... \n",
      "57/262... \n",
      "58/262... \n",
      "59/262... \n",
      "60/262... \n",
      "61/262... \n",
      "62/262... \n",
      "63/262... \n",
      "64/262... \n",
      "65/262... \n",
      "66/262... \n",
      "67/262... \n",
      "68/262... \n",
      "69/262... \n",
      "70/262... \n",
      "71/262... \n",
      "72/262... \n",
      "73/262... \n",
      "74/262... \n",
      "75/262... \n",
      "76/262... \n",
      "77/262... \n",
      "78/262... \n",
      "79/262... \n",
      "80/262... \n",
      "81/262... \n",
      "82/262... \n",
      "83/262... \n",
      "84/262... \n",
      "85/262... \n",
      "86/262... \n",
      "87/262... \n",
      "88/262... \n",
      "89/262... \n",
      "90/262... \n",
      "91/262... \n",
      "92/262... \n",
      "93/262... \n",
      "94/262... \n",
      "95/262... \n",
      "96/262... \n",
      "97/262... \n",
      "98/262... \n",
      "99/262... \n",
      "100/262... \n",
      "101/262... \n",
      "102/262... \n",
      "103/262... \n",
      "104/262... \n",
      "105/262... \n",
      "106/262... \n",
      "107/262... \n",
      "108/262... \n",
      "109/262... \n",
      "110/262... \n",
      "111/262... \n",
      "112/262... \n",
      "113/262... \n",
      "114/262... \n",
      "115/262... \n",
      "116/262... \n",
      "117/262... \n",
      "118/262... \n",
      "119/262... \n",
      "120/262... \n",
      "121/262... \n",
      "122/262... \n",
      "123/262... \n",
      "124/262... \n",
      "125/262... \n",
      "126/262... \n",
      "127/262... \n",
      "128/262... \n",
      "129/262... \n",
      "130/262... \n",
      "131/262... \n",
      "132/262... \n",
      "133/262... \n",
      "134/262... \n",
      "135/262... \n",
      "136/262... \n",
      "137/262... \n",
      "138/262... \n",
      "139/262... \n",
      "140/262... \n",
      "141/262... \n",
      "142/262... \n",
      "143/262... \n",
      "144/262... \n",
      "145/262... \n",
      "146/262... \n",
      "147/262... \n",
      "148/262... \n",
      "149/262... \n",
      "150/262... \n",
      "151/262... \n",
      "152/262... \n",
      "153/262... \n",
      "154/262... \n",
      "155/262... \n",
      "156/262... \n",
      "157/262... \n",
      "158/262... \n",
      "159/262... \n",
      "160/262... \n",
      "161/262... \n",
      "162/262... \n",
      "163/262... \n",
      "164/262... \n",
      "165/262... \n",
      "166/262... \n",
      "167/262... \n",
      "168/262... \n",
      "169/262... \n",
      "170/262... \n",
      "171/262... \n",
      "172/262... \n",
      "173/262... \n",
      "174/262... \n",
      "175/262... \n",
      "176/262... \n",
      "177/262... \n",
      "178/262... \n",
      "179/262... \n",
      "180/262... \n",
      "181/262... \n",
      "182/262... \n",
      "183/262... \n",
      "184/262... \n",
      "185/262... \n",
      "186/262... \n",
      "187/262... \n",
      "188/262... \n",
      "189/262... \n",
      "190/262... \n",
      "191/262... \n",
      "192/262... \n",
      "193/262... \n",
      "194/262... \n",
      "195/262... \n",
      "196/262... \n",
      "197/262... \n",
      "198/262... \n",
      "199/262... \n",
      "200/262... \n",
      "201/262... \n",
      "202/262... \n",
      "203/262... \n",
      "204/262... \n",
      "205/262... \n",
      "206/262... \n",
      "207/262... \n",
      "208/262... \n",
      "209/262... \n",
      "210/262... \n",
      "211/262... \n",
      "212/262... \n",
      "213/262... \n",
      "214/262... \n",
      "215/262... \n",
      "216/262... \n",
      "217/262... \n",
      "218/262... \n",
      "219/262... \n",
      "220/262... \n",
      "221/262... \n",
      "222/262... \n",
      "223/262... \n",
      "224/262... \n",
      "225/262... \n",
      "226/262... \n",
      "227/262... \n",
      "228/262... \n",
      "229/262... \n",
      "230/262... \n",
      "231/262... \n",
      "232/262... \n",
      "233/262... \n",
      "234/262... \n",
      "235/262... \n",
      "236/262... \n",
      "237/262... \n",
      "238/262... \n",
      "239/262... \n",
      "240/262... \n",
      "241/262... \n",
      "242/262... \n",
      "243/262... \n",
      "244/262... \n",
      "245/262... \n",
      "246/262... \n",
      "247/262... \n",
      "248/262... \n",
      "249/262... \n",
      "250/262... \n",
      "251/262... \n",
      "252/262... \n",
      "253/262... \n",
      "254/262... \n",
      "255/262... \n",
      "256/262... \n",
      "257/262... \n",
      "258/262... \n",
      "259/262... \n",
      "260/262... \n",
      "261/262... "
     ]
    }
   ],
   "source": [
    "cluster_faces(\"all_pictures/faces_nobg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df, dims):\n",
    "    \n",
    "    image = np.zeros(dims, dtype=np.uint8)\n",
    "    \n",
    "    df[\"summed\"] = (df.iloc[:, 5:]).sum(axis=1)\n",
    "    df = df.query(\"summed > 10\")\n",
    "    median_color = np.array(df[[\"b\", \"g\", \"r\"]].median(axis=0)) * 255\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        r, c = row[3], row[4]\n",
    "        image[int(r), int(c)] = median_color\n",
    "        \n",
    "    # make a color block\n",
    "    color_block = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "    color_block[:, :] = median_color\n",
    "        \n",
    "    # save image\n",
    "    cv2.imwrite(\"all_pictures/median/190_01_2000_1/median_face.jpg\", image)\n",
    "    cv2.imwrite(\"all_pictures/median/190_01_2000_1/median.jpg\", color_block)\n",
    "    \n",
    "    return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          r         g         b  row   col    gl3    h2   hs2   hs3     r3  \\\n",
      "0  0.494118  0.286275  0.176471  0.0   3.0  False  True  True  True  False   \n",
      "1  0.537255  0.294118  0.196078  0.0   4.0  False  True  True  True  False   \n",
      "2  0.670588  0.372549  0.282353  0.0   5.0  False  True  True  True  False   \n",
      "3  0.952941  0.419608  0.235294  0.0  11.0  False  True  True  True   True   \n",
      "4  0.980392  0.411765  0.231373  0.0  12.0  False  True  True  True   True   \n",
      "\n",
      "   ...    rgb2   rgb3  rgbh3  rgbhs2  rgbhsl2  rgbhsl3   rh2  rhs2  \\\n",
      "0  ...   False  False  False   False    False    False  True  True   \n",
      "1  ...   False  False  False   False    False    False  True  True   \n",
      "2  ...   False  False  False   False    False    False  True  True   \n",
      "3  ...    True  False   True    True     True     True  True  True   \n",
      "4  ...    True  False   True    True     True     True  True  True   \n",
      "\n",
      "   rhscenter3    s2  \n",
      "0       False  True  \n",
      "1       False  True  \n",
      "2       False  True  \n",
      "3       False  True  \n",
      "4       False  True  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_pictures/median/190_01_2000_1/pixels.csv\")\n",
    "print(df.head())\n",
    "combine(df, (500, 500, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
